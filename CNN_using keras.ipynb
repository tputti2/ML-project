{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('AGG')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import (Activation, Conv3D, Dense, Dropout, Flatten,\n",
    "                          MaxPooling3D)\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import initializerstializers\n",
    "\n",
    "from keras.layers import merge\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_parallel(model, gpu_count):\n",
    "    def get_slice(data, idx, parts):\n",
    "        shape = tf.shape(data)\n",
    "        size = tf.concat([ shape[:1] // parts, shape[1:] ],axis=0)\n",
    "        stride = tf.concat([ shape[:1] // parts, shape[1:]*0 ],axis=0)\n",
    "        start = stride * idx\n",
    "        return tf.slice(data, start, size)\n",
    "\n",
    "    outputs_all = []\n",
    "    for i in range(len(model.outputs)):\n",
    "        outputs_all.append([])\n",
    "\n",
    "    #Place a copy of the model on each GPU, each getting a slice of the batch\n",
    "    for i in range(gpu_count):\n",
    "        with tf.device('/gpu:%d' % i):\n",
    "            with tf.name_scope('tower_%d' % i) as scope:\n",
    "\n",
    "                inputs = []\n",
    "                #Slice each input into a piece for processing on this GPU\n",
    "                for x in model.inputs:\n",
    "                    input_shape = tuple(x.get_shape().as_list())[1:]\n",
    "                    slice_n = Lambda(get_slice, output_shape=input_shape, arguments={'idx':i,'parts':gpu_count})(x)\n",
    "                    inputs.append(slice_n)                \n",
    "\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                if not isinstance(outputs, list):\n",
    "                    outputs = [outputs]\n",
    "                \n",
    "                #Save all the outputs for merging back together later\n",
    "                for l in range(len(outputs)):\n",
    "                    outputs_all[l].append(outputs[l])\n",
    "\n",
    "    # merge outputs on CPU\n",
    "    with tf.device('/cpu:0'):\n",
    "        merged = []\n",
    "        for outputs in outputs_all:\n",
    "            merged.append(merge(outputs, mode='concat', concat_axis=0))\n",
    "            \n",
    "        return Model(input=model.inputs, output=merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='simple 3D convolution for action recognition')\n",
    "    parser.add_argument('--batch', type=int, default=128)\n",
    "    parser.add_argument('--epoch', type=int, default=100)\n",
    "    parser.add_argument('--nclass', type=int, default=101)\n",
    "    parser.add_argument('--output', type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    Y = np.load('train_binary_Y.npy')\n",
    "    x = np.load('train_X.npy')\n",
    "    x_test = np.load('valid_test_X.npy')\n",
    "    X = x.reshape((x.shape[0], 26, 31, 23, 1))\n",
    "    X_Test = x_test.reshape((x_test.shape[0], 26, 31, 23, 1))\n",
    "    print(X.shape)\n",
    "    print('X_shape:{}\\nY_shape:{}'.format(X.shape, Y.shape))\n",
    "\n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(64, kernel_size=(3, 3, 3), input_shape=(\n",
    "        X.shape[1:]), border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv3D(64, kernel_size=(3, 3, 3), border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(3, 3, 3), border_mode='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv3D(128, kernel_size=(3, 3, 3), border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv3D(128, kernel_size=(3, 3, 3), border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(3, 3, 3), border_mode='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #kernel_initializer=initializers.RandomNormal(stddev=0.002762)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, init = 'uniform' , activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512,init = 'uniform', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(19,init = 'uniform', activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=binary_crossentropy,\n",
    "                  optimizer=Adam(), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True,\n",
    "               to_file=os.path.join(args.output, 'model.png'))\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.1, random_state=43)\n",
    "\n",
    "    history = model.fit(X, Y, validation_data=(X_test, Y_test), batch_size=args.batch,\n",
    "                        epochs=args.epoch, verbose=1, shuffle=True)\n",
    "    model.evaluate(X_test, Y_test, verbose=0)\n",
    "    model_json = model.to_json()\n",
    "    Y_Test = model.predict(X_Test)\n",
    "    #Y_Test[Y_Test>=0.5] = 1\n",
    "    #Y_Test[Y_Test<0.5] = 0\n",
    "    np.save('y_keras.npy', Y_Test)\n",
    "    loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test loss:', loss)\n",
    "    print('Test accuracy:', acc)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
